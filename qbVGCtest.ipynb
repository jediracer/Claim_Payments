{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import mysql.connector as mc\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pdfkit\n",
    "import win32com.client as wc\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "import ssl\n",
    "import smtplib\n",
    "import os\n",
    "import pysftp\n",
    "\n",
    "# Get db credentials\n",
    "from configTest import mysql_host, mysql_u, mysql_pw, vgc_host, vgc_u, vgc_pw, smtp_host, e_user, e_pw, port, sftp_h, sftp_u, sftp_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns in DFs\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL\n",
    "def mysql_q (u, p, h, db, sql, cols, commit):\n",
    "    # cols (0 = no, 1 = yes)\n",
    "    # commit (select = 0, insert/update = 1)\n",
    "\n",
    "    # connect to claim_qb_payments db\n",
    "    cnx = mc.connect(user=u, password=p,\n",
    "                    host=h,\n",
    "                    database=db)\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "    # commit?\n",
    "    if commit == 1:\n",
    "        cursor.execute(sql)\n",
    "        cnx.commit()\n",
    "        sql_result = 0     \n",
    "    else:\n",
    "        cursor.execute(sql)\n",
    "        sql_result = cursor.fetchall()\n",
    "\n",
    "    # columns ?\n",
    "    if cols == 1:\n",
    "        columns=list([x[0] for x in cursor.description])\n",
    "        # close connection\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        # return query result [0] and columns [1]\n",
    "        return sql_result\n",
    "    else:\n",
    "        # close connection\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        # return query result\n",
    "        return sql_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email\n",
    "def send_email(toEmail, subject, msg_html, attachPath='', *args):\n",
    "    fromEmail = 'claims@visualgap.com'\n",
    "\n",
    "    # address message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = fromEmail\n",
    "    msg['To'] = ','.join(toEmail)\n",
    "\n",
    "    # create body\n",
    "    body_html = MIMEText(msg_html, 'html')\n",
    "    msg.attach(body_html) \n",
    "\n",
    "    for arg in args:\n",
    "        fName = ''.join([attachPath, arg])\n",
    "        filename = os.path.abspath(fName)\n",
    "\n",
    "        with open(filename, 'rb') as fn:\n",
    "            attachment = MIMEApplication(fn.read())\n",
    "            attachment.add_header('Content-Disposition', 'attachment', filename=arg)\n",
    "            msg.attach(attachment)\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_host, port)\n",
    "        # check connection\n",
    "        server.ehlo()  \n",
    "        # Secure the connection\n",
    "        server.starttls(context=context)  \n",
    "        # check connection\n",
    "        server.ehlo()\n",
    "        server.login(e_user, e_pw)\n",
    "        # Send email\n",
    "        server.sendmail(fromEmail, toEmail, msg.as_string())\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print any error messages\n",
    "        print(e)\n",
    "    finally:\n",
    "        server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir (path, ext):\n",
    "    for x in os.listdir(path):\n",
    "        if x.endswith(ext):\n",
    "            os.remove(os.path.join(path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "attachment_dir = 'S:/claims/letters/attachment/'\n",
    "file_staging_dir = './letters/staging/'\n",
    "# get current date\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "attach_name = f'Claims_Paid_{now.strftime(\"%Y-%m-%d\")}'\n",
    "attach_file = f'{attachment_dir}{attach_name}'\n",
    "html_file = f'{file_staging_dir}final_rpt.html'\n",
    "err_html_file = f'{file_staging_dir}error.html'\n",
    "csv_file = f'{file_staging_dir}final_rpt.csv'\n",
    "err_csv_file = f'{file_staging_dir}error.csv'\n",
    "template_file = './html/pymt_summary_template.html'\n",
    "html_file2 = './letters/staging/Claims_Paid.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql query to collect qb_txnid's\n",
    "sql = '''\n",
    "      SELECT rtbp_id, check_nbr, qb_txnid\n",
    "      FROM ready_to_be_paid\n",
    "      WHERE toVGC = 1\n",
    "        AND qb_txnid <> '0';\n",
    "      '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save query results as DF\n",
    "qb_df = pd.DataFrame(mysql_q(mysql_u, mysql_pw, mysql_host, 'claim_qb_payments', sql, 0, 0))\n",
    "\n",
    "# add column names\n",
    "qb_df_cols = ['rtbp_id','check_nbr', 'qb_txnid']\n",
    "qb_df.columns = qb_df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Quickbooks\n",
    "try:\n",
    "    sessionManager = wc.Dispatch(\"QBXMLRP2.RequestProcessor\")    \n",
    "    sessionManager.OpenConnection('', 'Claim Payments')\n",
    "    ticket = sessionManager.BeginSession(\"\", 2)\n",
    "except Exception as e:\n",
    "    print('''\n",
    "    Make sure QuickBooks is running and you are logged into the Company File.\n",
    "    ERROR: {}'''.format(e))\n",
    "    sys.exit(\"Error with communicating with QuickBooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qbxml to query qb for check numbers\n",
    "try:\n",
    "    for index, row in qb_df.iterrows():\n",
    "        qbxmlQuery = '''\n",
    "                    <?qbxml version=\"14.0\"?>\n",
    "                    <QBXML>\n",
    "                        <QBXMLMsgsRq onError=\"stopOnError\">\n",
    "                            <CheckQueryRq>\n",
    "                                <TxnID>{txnId}</TxnID> \n",
    "                            </CheckQueryRq>\n",
    "                        </QBXMLMsgsRq>\n",
    "                    </QBXML>\n",
    "                    '''.format(txnId=row['qb_txnid'])\n",
    "\n",
    "        # Send query and receive response\n",
    "        responseString = sessionManager.ProcessRequest(ticket, qbxmlQuery)\n",
    "\n",
    "        # output Check Number (RefNumber)\n",
    "        QBXML = ET.fromstring(responseString)\n",
    "        QBXMLMsgsRs = QBXML.find('QBXMLMsgsRs')\n",
    "        checkResults = QBXMLMsgsRs.iter(\"CheckRet\")\n",
    "        chkNbr = '0'\n",
    "        for checkResult in checkResults:\n",
    "            chkNbr = checkResult.find('RefNumber').text\n",
    "\n",
    "        # Add Check Number to ready_to_be_paid table\n",
    "        qb_sql_file = '''UPDATE ready_to_be_paid\n",
    "                    SET check_nbr = '{ChkNbr}'\n",
    "                    WHERE rtbp_id = {rowID};'''.format(ChkNbr=chkNbr, rowID=row['rtbp_id'])\n",
    "        \n",
    "        # execute and commit sql\n",
    "        mysql_q(mysql_u, mysql_pw, mysql_host, 'claim_qb_payments', qb_sql_file, 0, 1)\n",
    "except Exception as e:\n",
    "    print('''\n",
    "    Make sure to print checks and process ACH in Quickbooks prior to starting this process.\n",
    "    ERROR: {}'''.format(e))\n",
    "    sys.exit(\"Error with communicating with QuickBooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect from Quickbooks\n",
    "sessionManager.EndSession(ticket)\n",
    "sessionManager.CloseConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql query for GAP claims that are RTBP\n",
    "sql = '''\n",
    "      SELECT r.rtbp_id, r.claim_id, r.claim_nbr, r.carrier_id, r.lender_name, r.pymt_method, r.first, r.last, r.pymt_type_id, r.amount, r.payment_category_id, r.check_nbr, r.qb_txnid, r.pymt_date, r.toVGC, r.err_msg\n",
    "      FROM ready_to_be_paid r\n",
    "      INNER JOIN (SELECT batch_id\n",
    "                  FROM ready_to_be_paid\n",
    "                  WHERE toVGC = 1\n",
    "                  GROUP BY batch_id) sq\n",
    "      USING(batch_id);\n",
    "      '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save query results as DF\n",
    "df = pd.DataFrame(mysql_q(mysql_u, mysql_pw, mysql_host, 'claim_qb_payments', sql, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names\n",
    "df_cols = ['rtbp_id', 'claim_id', 'claim_nbr', 'carrier_id', 'lender_name', 'pymt_method', 'first', 'last', 'pymt_type_id', 'amount', 'payment_category_id', 'check_nbr', 'qb_txnid', 'pymt_date', 'toVGC', 'err_msg']\n",
    "\n",
    "df.columns = df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add carrier name\n",
    "sql = '''\n",
    "    SELECT carrier_id, description\n",
    "    FROM carriers;\n",
    "    '''\n",
    "# save query results as DF\n",
    "carrier_df = pd.DataFrame(mysql_q(vgc_u, vgc_pw, vgc_host, 'visualgap_claims', sql, 0, 0))\n",
    "\n",
    "col_names = ['carrier_id', 'carrier']\n",
    "carrier_df.columns = col_names\n",
    "\n",
    "# Merge QB_ListID into df\n",
    "df = df.merge(carrier_df, left_on='carrier_id', right_on='carrier_id').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format df\n",
    "# list of conditions\n",
    "type_conds = [((df['payment_category_id'] == 1) & (df['pymt_type_id'] == 1)),\n",
    "              ((df['payment_category_id'] == 1) & (df['pymt_type_id'] == 2)),\n",
    "              ((df['payment_category_id'] == 2) & (df['pymt_type_id'] == 1)),\n",
    "              ((df['payment_category_id'] == 2) & (df['pymt_type_id'] == 2)),\n",
    "              ((df['payment_category_id'] == 3) & (df['pymt_type_id'] == 1)),\n",
    "              ((df['payment_category_id'] == 3) & (df['pymt_type_id'] == 2))]\n",
    "# list of name types\n",
    "type_name = ['GAP', 'GAP Supp', 'GAP Plus', 'GAP Plus Supp', 'TotalRestart', 'TotalRestart Supp']\n",
    "\n",
    "# add column and assigned values\n",
    "df['Claim_Type'] = np.select(type_conds, type_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to update VGC\n",
    "# vgc_update_df = df[['claim_id', 'pymt_method', 'pymt_type_id', 'amount', 'payment_category_id', 'check_nbr', 'qb_txnid', 'pymt_date']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format amount\n",
    "df['amount'] = df['amount'].map('${:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for Claim Payment Summary\n",
    "final_rpt_df = df[['claim_nbr', 'carrier', 'lender_name', 'first', 'last', 'amount', 'pymt_method', 'check_nbr', 'pymt_date', 'Claim_Type']].loc[df['toVGC'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format df\n",
    "final_rpt_df.rename(columns = {'claim_nbr':'Claim Nbr', 'carrier':'Carrier', 'lender_name':'Lender', 'first':'First Name', 'last':'Last Name', 'amount':'Amount', 'pymt_method':'Method',\n",
    "                               'check_nbr':'Check Nbr', 'pymt_date': 'Date', 'Claim_Type':'Claim Type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rpt_df.sort_values(by = ['Carrier', 'Last Name', 'First Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create error_df\n",
    "error_df = df[['claim_nbr', 'lender_name', 'first', 'last', 'err_msg']].loc[df['toVGC'] == 2].copy()\n",
    "\n",
    "# Format df\n",
    "error_df.rename(columns = {'claim_nbr':'Claim Nbr', 'lender_name':'Lender', 'first':'First Name', 'last':'Last Name', 'err_msg':'Error Message'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export is df as csv\n",
    "final_rpt_df.to_csv(csv_file, index=False)\n",
    "error_df.to_csv(err_csv_file, index=False)\n",
    "# read in csv\n",
    "csvFile = pd.read_csv(csv_file)\n",
    "errCsvFile = pd.read_csv(err_csv_file)\n",
    "# convert csv to html\n",
    "csvFile.to_html(html_file, index=False)\n",
    "errCsvFile.to_html(err_html_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get html df\n",
    "soup = Soup(open(html_file), \"html.parser\")\n",
    "err_soup = Soup(open(err_html_file), \"html.parser\")\n",
    "table = str(soup.select_one(\"table\", {\"class\":\"dataframe\"}))\n",
    "err_table = str(err_soup.select_one(\"table\", {\"class\":\"dataframe\"}))\n",
    "\n",
    "# Get template\n",
    "soup2 = Soup(open(template_file), \"html.parser\")\n",
    "# Find and insert payment table\n",
    "df_div = soup2.find(\"div\", {\"id\":\"df\"})\n",
    "df_div.append(Soup(table, 'html.parser'))\n",
    "# Find and insert error table\n",
    "err_div = soup2.find(\"div\", {\"id\":\"error\"})\n",
    "err_div.append(Soup(err_table, 'html.parser'))\n",
    "\n",
    "# write html file\n",
    "with open(html_file2,'w') as file:\n",
    "    file.write(str(soup2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if file exists\n",
    "fName = ''.join([attach_file, '.pdf'])\n",
    "fnNum = 0\n",
    "\n",
    "while(os.path.isfile(fName) == True):\n",
    "    fnNum += 1\n",
    "    fName = ''.join([attach_file, '_', str(fnNum), '.pdf']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PDF from html\n",
    "pdf_options = {'orientation': 'landscape',\n",
    "                'page-size': 'Letter',\n",
    "                'margin-top': '0.25in',\n",
    "                'margin-right': '0.25in',\n",
    "                'margin-bottom': '0.25in',\n",
    "                'margin-left': '0.25in',\n",
    "                'encoding': \"UTF-8\",}\n",
    "                \n",
    "pdfkit.from_file(html_file2, fName, options=pdf_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Claim Summary Report\n",
    "to = ['jared@visualgap.com']\n",
    "sub = f'Claim Payment Summary {now.strftime(\"%Y-%m-%d\")}'\n",
    "msg_html = '''\n",
    "            <html>\n",
    "            <body>\n",
    "                <p>Attached is the Claim Summary Report.<br>\n",
    "                <br>\n",
    "                Thank you, <br>\n",
    "                Claims Department <br>\n",
    "                <br>\n",
    "                <b>Frost Financial Services, Inc. | VisualGAP <br>\n",
    "                Claims Department <br>\n",
    "                Phone: 888-753-7678 Option 3</b>\n",
    "                </p>\n",
    "            </body>\n",
    "            </html>\n",
    "           '''\n",
    "if fnNum == 0:\n",
    "    a_file = ''.join([attach_name, '.pdf'])\n",
    "else:\n",
    "    a_file = ''.join([attach_name, '_', str(fnNum), '.pdf'])\n",
    "\n",
    "send_email(to, sub, msg_html, attachment_dir, a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data file for SCC\n",
    "scc_cols = ['Carrier', 'claim_nbr_end', 'blank1', 'policy', 'blank2', 'last', 'first', 'loss_type', 'loss_date', 'blank3', 'GAP_static', 'GAP_amount', 'blank4', \n",
    "            'blank5', 'blank6', 'lender', 'address', 'blank7', 'city', 'state', 'zip', 'status', 'blank8', 'GAP_static2', 'contract_id', 'vin', 'make',\n",
    "            'model', 'year', 'claim_nbr_front', 'CHECK', 'pymt_code', 'blank9', 'blank10', 'PAID_static', 'status_date', 'blank11', 'status_date2', 'blank12',\n",
    "            'FFS_static', 'chk_nbr']\n",
    "scc_df = pd.DataFrame(columns = scc_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SCC claims\n",
    "scc_rpt_df = df[['rtbp_id', 'claim_id', 'amount', 'check_nbr', 'Claim_Type']].loc[(df['toVGC'] == 1) & (df['carrier_id'] == 8)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format amount without $, commas, and decimals\n",
    "scc_rpt_df.replace('[\\$,\\.]','', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scc_file df\n",
    "scc_file_df = pd.DataFrame()\n",
    "\n",
    "# Get SCC claim data\n",
    "if len(scc_rpt_df) > 0:\n",
    "    for index, row in scc_rpt_df.iterrows():\n",
    "        # Check or '' & payment code\n",
    "        if row['amount'] == '$0.00':\n",
    "            check = ''\n",
    "            p_code = '003'\n",
    "        else:\n",
    "            check = 'CHECK'\n",
    "            p_code = '001'\n",
    "        # Paid or Plus\n",
    "        if 'Plus' in row['Claim_Type']:\n",
    "            paid_or_plus = 'PLUS'\n",
    "        else:\n",
    "            paid_or_plus = 'PAID'\n",
    "        # ACH in chk_nbr to 0 \n",
    "        if 'ACH' in row['check_nbr']:\n",
    "            chk_num = '0'\n",
    "        else:\n",
    "            chk_num = row['check_nbr']            \n",
    "        # create query\n",
    "        sql = '''\n",
    "                SELECT 'SC' AS Carrier, \n",
    "                SUBSTRING(c.claim_nbr, CHAR_LENGTH(c.claim_nbr)-5, 5) AS claim_nbr_end,\n",
    "                '' AS blank1,\n",
    "                l.policy_nbr,\n",
    "                '' AS blank2,\n",
    "                SUBSTRING(b.last, 1, 30) AS lastn,\n",
    "                SUBSTRING(b.first, 1, 30) AS firstn,\n",
    "                CASE\n",
    "                    WHEN c.loss_type_id=1 THEN 'CO'\n",
    "                    WHEN c.loss_type_id=2 THEN 'TH'\n",
    "                    WHEN c.loss_type_id=3 THEN 'WE'\n",
    "                    ELSE 'OT'\n",
    "                END AS loss_type,\n",
    "                DATE_FORMAT(c.loss_date, \"%Y%m%d\") AS loss_date,\n",
    "                '' AS blank3,\n",
    "                'GAP' AS GAP_static,\n",
    "                '{amt}' AS GAP_amount,\n",
    "                '' AS blank4,\n",
    "                '' AS blank5,\n",
    "                '' AS blank6,\n",
    "                SUBSTRING(l.alt_name, 1, 32) AS lender,\n",
    "                SUBSTRING(l.address1, 1, 32) AS address,\n",
    "                '' AS blank7,\n",
    "                l.city,\n",
    "                l.state,\n",
    "                SUBSTRING(l.zip, 1, 5) AS zip,\n",
    "                'C' AS status,\n",
    "                '' AS blank8,\n",
    "                'GAP' AS GAP_static2,\n",
    "                c.contractId,\n",
    "                v.vin,\n",
    "                SUBSTRING(v.make, 1, 20) AS Make,\n",
    "                SUBSTRING(v.model, 1, 20) AS Model,\n",
    "                SUBSTRING(v.year, 2, 2) AS Year,\n",
    "                SUBSTRING(c.claim_nbr, 1, 8) AS claim_nbr_front,\n",
    "                '{chk}' AS Chk,\n",
    "                '{pay_code}' AS pymt_code,\n",
    "                '' AS blank9,\n",
    "                '' AS blank10,\n",
    "                '{paid_plus}' AS PAID_static,\n",
    "                DATE_FORMAT(CURDATE(), \"%Y%m%d\") AS status_date,\n",
    "                '' AS blank11,\n",
    "                DATE_FORMAT(CURDATE(), \"%Y%m%d\") AS status_date2,\n",
    "                '' AS blank12,\n",
    "                'FFS' AS FFS_static,\n",
    "                '{check_nbr}' AS Chk_nbr       \n",
    "            FROM claims c\n",
    "            INNER JOIN claim_lender l\n",
    "                USING(claim_id)\n",
    "            INNER JOIN claim_borrower b\n",
    "                USING(claim_id)\n",
    "            INNER JOIN claim_vehicle v\n",
    "                USING(claim_id)\n",
    "            WHERE c.claim_id = {claimId};\n",
    "              '''.format(claimId=row['claim_id'], amt=row['amount'], chk=check, pay_code=p_code, paid_plus=paid_or_plus, check_nbr=chk_num)\n",
    "\n",
    "        temp_df = pd.DataFrame(mysql_q(vgc_u, vgc_pw, vgc_host, 'visualgap_claims', sql, 0, 0))    \n",
    "        scc_file_df = scc_file_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill each field has an exact starting position\n",
    "#A\n",
    "scc_file_df[0] = scc_file_df[0].str.pad(2, side='right', fillchar=' ')\n",
    "#B\n",
    "scc_file_df[1] = scc_file_df[1].str.pad(8, side='right', fillchar=' ')\n",
    "#C\n",
    "scc_file_df[2] = scc_file_df[2].str.pad(12, side='right', fillchar=' ')\n",
    "#D\n",
    "scc_file_df[3] = scc_file_df[3].str.pad(15, side='right', fillchar=' ')\n",
    "#E\n",
    "scc_file_df[4] = scc_file_df[4].str.pad(32, side='right', fillchar=' ')\n",
    "#F\n",
    "scc_file_df[5] = scc_file_df[5].str.pad(30, side='right', fillchar=' ')\n",
    "#G\n",
    "scc_file_df[6] = scc_file_df[6].str.pad(30, side='right', fillchar=' ')\n",
    "#H\n",
    "scc_file_df[7] = scc_file_df[7].str.pad(2, side='right', fillchar=' ')\n",
    "#I\n",
    "scc_file_df[8] = scc_file_df[8].str.pad(8, side='right', fillchar=' ')\n",
    "#J\n",
    "scc_file_df[9] = scc_file_df[9].str.pad(9, side='right', fillchar=' ')\n",
    "#K\n",
    "scc_file_df[10] = scc_file_df[10].str.pad(3, side='right', fillchar=' ')\n",
    "#L\n",
    "scc_file_df[11] = scc_file_df[11].str.pad(9, side='left', fillchar='0')\n",
    "#M\n",
    "scc_file_df[12] = scc_file_df[12].str.pad(9, side='right', fillchar=' ')\n",
    "#N\n",
    "scc_file_df[13] = scc_file_df[13].str.pad(9, side='right', fillchar=' ')\n",
    "#O\n",
    "scc_file_df[14] = scc_file_df[14].str.pad(10, side='right', fillchar=' ')\n",
    "#P\n",
    "scc_file_df[15] = scc_file_df[15].str.pad(32, side='right', fillchar=' ')\n",
    "#Q\n",
    "scc_file_df[16] = scc_file_df[16].str.pad(32, side='right', fillchar=' ')\n",
    "#R\n",
    "scc_file_df[17] = scc_file_df[17].str.pad(32, side='right', fillchar=' ')\n",
    "#S\n",
    "scc_file_df[18] = scc_file_df[18].str.pad(30, side='right', fillchar=' ')\n",
    "#T\n",
    "scc_file_df[19] = scc_file_df[19].str.pad(2, side='right', fillchar=' ')\n",
    "#U\n",
    "scc_file_df[20] = scc_file_df[20].str.pad(9, side='right', fillchar=' ')\n",
    "#V\n",
    "scc_file_df[21] = scc_file_df[21].str.pad(1, side='right', fillchar=' ')\n",
    "#W\n",
    "scc_file_df[22] = scc_file_df[22].str.pad(1, side='right', fillchar=' ')\n",
    "#X\n",
    "scc_file_df[23] = scc_file_df[23].str.pad(3, side='right', fillchar=' ')\n",
    "#Y\n",
    "scc_file_df[24] = scc_file_df[24].str.pad(20, side='right', fillchar=' ')\n",
    "#Z\n",
    "scc_file_df[25] = scc_file_df[25].str.pad(18, side='right', fillchar=' ')\n",
    "#AA\n",
    "scc_file_df[26] = scc_file_df[26].str.pad(20, side='right', fillchar=' ')\n",
    "#AB\n",
    "scc_file_df[27] = scc_file_df[27].str.pad(20, side='right', fillchar=' ')\n",
    "#AC\n",
    "scc_file_df[28] = scc_file_df[28].str.pad(2, side='right', fillchar=' ')\n",
    "#AD\n",
    "scc_file_df[29] = scc_file_df[29].str.pad(8, side='right', fillchar=' ')\n",
    "#AE\n",
    "scc_file_df[30] = scc_file_df[30].str.pad(20, side='right', fillchar=' ')\n",
    "#AF\n",
    "scc_file_df[31] = scc_file_df[31].str.pad(3, side='right', fillchar=' ')\n",
    "#AG\n",
    "scc_file_df[32] = scc_file_df[32].str.pad(20, side='right', fillchar=' ')\n",
    "#AH\n",
    "scc_file_df[33] = scc_file_df[33].str.pad(8, side='right', fillchar=' ')\n",
    "#AI\n",
    "scc_file_df[34] = scc_file_df[34].str.pad(20, side='right', fillchar=' ')\n",
    "#AJ\n",
    "scc_file_df[35] = scc_file_df[35].str.pad(8, side='right', fillchar=' ')\n",
    "#AK\n",
    "scc_file_df[36] = scc_file_df[36].str.pad(30, side='right', fillchar=' ')\n",
    "#AL\n",
    "scc_file_df[37] = scc_file_df[37].str.pad(8, side='right', fillchar=' ')\n",
    "#AM\n",
    "scc_file_df[38] = scc_file_df[38].str.pad(10, side='right', fillchar=' ')\n",
    "#AN\n",
    "scc_file_df[39] = scc_file_df[39].str.pad(3, side='right', fillchar=' ')\n",
    "#AO\n",
    "scc_file_df[40] = scc_file_df[40].str.pad(8, side='left', fillchar='0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write text file\n",
    "with open(attachment_dir + 'FrostGAP.txt', 'a') as f:\n",
    "    for index, row in scc_file_df.iterrows():\n",
    "        col_index = 0\n",
    "        while col_index != len(row):\n",
    "            f.write(row[col_index])\n",
    "            col_index += 1\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable host key checking\n",
    "cnopts = pysftp.CnOpts()\n",
    "cnopts.hostkeys = None\n",
    "\n",
    "# Send file to SCC via SFTP\n",
    "with pysftp.Connection(sftp_h, username=sftp_u, password=sftp_p, cnopts=cnopts) as sftp:\n",
    "    with sftp.cd('dropoff'):\n",
    "        sftp.put(attachment_dir + 'FrostGAP.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send Email notification to SCC and Claims\n",
    "to = ['jared@visualgap.com']\n",
    "sub = f'Frost claim file'\n",
    "msg_html = '''\n",
    "            <html>\n",
    "            <body>\n",
    "                <p>Hello,<br>\n",
    "                <br>\n",
    "                We have submitted a new claim file today.  If you have any questions or concerns please contact us. <br>\n",
    "                <br>\n",
    "                Thank you, <br>\n",
    "                Claims Department <br>\n",
    "                <br>\n",
    "                <b>Frost Financial Services, Inc. | VisualGAP <br>\n",
    "                Claims Department <br>\n",
    "                Phone: 888-753-7678 Option 3</b>\n",
    "                </p>\n",
    "            </body>\n",
    "            </html>\n",
    "           '''\n",
    "send_email(to, sub, msg_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update toVGC to 3\n",
    "if len(df) > 0:\n",
    "    for index, row in df.iterrows():\n",
    "        err_sql = '''\n",
    "                UPDATE ready_to_be_paid\n",
    "                SET toVGC = 3\n",
    "                WHERE rtbp_id = {rtbp_id};\n",
    "                '''.format(rtbp_id=row['rtbp_id'])\n",
    "        # run update query        \n",
    "        mysql_q(mysql_u, mysql_pw, mysql_host, 'claim_qb_payments', err_sql, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove files from staging directory\n",
    "file_ext = [\".csv\", \".html\"]\n",
    "file_staging_dir = './letters/staging/'\n",
    "\n",
    "for ext in file_ext:\n",
    "    clear_dir(file_staging_dir, ext)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25bbdcee2c7b2635f2af9203b4c23ac3a2ece7544aac2f4db010efbeb60ffe95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyfrost32-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
